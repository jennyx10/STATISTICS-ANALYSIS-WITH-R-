---
title: "Teaching Model 1.5"
author: "Module2"
date: '2023-04-20'
output: html_document
---

5 Batch Effect and Factor Analysis

In this module, we will consider batch effect, which is used to explain how different on effect from between group and from within group for model construction.We still want to construct a linear model, the difference from the previous linear model fit and fit_ in which we used the data is different from other models such as KNN model, and we have the uncertainty to the models we constructed. Moreover, we also want to study which factor(s) has an impact to the variances in term of gender. 

```{r}
library(rafalib)
library(dplyr)
colgmx <- apply(as.matrix(colgtotal), 2, as.numeric)
colgmx <- colgmx[,6:11]

colgmx <- colgmx - rowMeans(colgmx)
colgmj3 <- colgmx[which(colgtotal$Major == '3'),]
mj3 <- colMeans(colgmx[which(colgtotal$Major == '3'),])
```
The follow histogram is describing both female and male performance regarding the mj3 group.

```{r}
mypar()
hist(mj3)

```
 
The negative change probably comes from male, which helps explain the variance difference we mentioned in module 1.1 for major 3.
```{r}

s <- svd(colgmx)
st <- svd(na.omit(colgtotal[,2:12]))
sv<- svd(colgmj3)

```


```{r}
What <- t(st$v[,1:2])
colnames(What)<-colnames(colgtotal[,2:12])
round(What,2)
```
The table shows how variable such as project is related to the whole groups and the difference between the group and the project 

```{r}
fitup = st$u[,1:2]%*% (st$d[1:2]*What)
var(as.vector(fitup))/var(as.vector(colgmx))

```
To construct a linear model, we look at the first two components, which help explain around 0.98 percent of the data.That is, we use factor analysis and PCA both to construct the model fitup. We can also add other remaining components to improve the model accurancy.   


Below plot shows the correlation about between groups is larger than that within groups.

```{r}
library(RColorBrewer)
cols=colorRampPalette(rev(brewer.pal(10,"RdBu")))(70)
image ( cor(colgmx) ,col=cols,zlim=c(-1,1))

plot(st$d^2/sum(st$d^2))

```




```{r}
mj <- factor(colgtotal$Major)
cols = as.numeric(mj)
mypar()
plot(st$v[,1],st$v[,2],col=cols,pch=16,
     xlab="PC1",ylab="PC2")
legend("bottomleft",levels(mj),col=seq(along=levels(mj)),pch=16)

```



```{r}
rc <- factor(colgtotal$Race)
cols = as.numeric(rc)
mypar()
plot(st$v[,1],st$v[,2],col=cols,pch=16,
     xlab="PC1",ylab="PC2")
legend("bottomleft",levels(rc),col=seq(along=levels(rc)),pch=16)

```


```{r}
gl <- factor(colgtotal$Goal)
cols = as.numeric(gl)
mypar()
plot(st$v[,1],st$v[,2],col=cols,pch=16,
     xlab="PC1",ylab="PC2")
legend("bottomleft",levels(gl),col=seq(along=levels(gl)),pch=16)

```
```{r}
b <- na.omit(colgtotal[,2:12])
colg <- apply(as.matrix(b), 2, as.numeric)
colg<-colg[,2:11] - rowMeans(colg[,2:11])

sv<- svd(colg)
```


```{r}
variable <- as.numeric(mj)
mypar(2,2)
for(i in 1:4){
  boxplot(split(st$v[,i],variable),las=2,range=0)
  stripchart(split(st$v[,i],variable),add=TRUE,vertical=TRUE,pch=1,cex=.5,col=1)
  }
```



```{r}
variable <- as.numeric(gd)
mypar(2,2)
for(i in 1:4){
  boxplot(split(st$v[,i],variable),las=2,range=0)
  stripchart(split(st$v[,i],variable),add=TRUE,vertical=TRUE,pch=1,cex=.5,col=1)
  }
```
```{r}
variable <- as.numeric(gl)
mypar(2,2)
for(i in 1:4){
  boxplot(split(st$v[,i],variable),las=2,range=0)
  stripchart(split(st$v[,i],variable),add=TRUE,vertical=TRUE,pch=1,cex=.5,col=1)
  }
```



```{r}
variable <- as.numeric(rc)
mypar(2,2)
for(i in 1:4){
  boxplot(split(st$v[,i],variable),las=2,range=0)
  stripchart(split(st$v[,i],variable),add=TRUE,vertical=TRUE,pch=1,cex=.5,col=1)
  }
```






```{r}
variable <- as.numeric(gd)
mypar(2,2)
for(i in 1:4){
  boxplot(split(sv$v[,i],variable),las=2,range=0)
  stripchart(split(sv$v[,i],variable),add=TRUE,vertical=TRUE,pch=1,cex=.5,col=1)
  }
```



The above box plots to each variable analysis by considering entire updated dataset. They explain correlation between the principal components and some factors such as mj, gl and rc, but unsure about gd. 


In addition, look at the mj3, however, there is apparent correlation between the first principal component and gender, which can be used to explain the finding in modular1 where significant variance caused by gender in particular sections.














