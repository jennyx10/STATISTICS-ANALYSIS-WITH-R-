---
title: "Teaching Model 1.2.4"
author: "Module2"
date: '2023-04-10'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

4. Model Prediction

We begin to do prediction using naive, KNN and random forest model for project model

```{r}
set.seed(1)
sample <- sample(c(TRUE, FALSE), nrow(colgtotal), replace=TRUE, prob=c(0.7,0.3))
train  <- colgtotal[sample, ]
test   <- colgtotal[!sample, ]

```


```{r}
x1 <- as.numeric(train[,8])
x2 <- as.numeric(train[,9])
x3 <- as.numeric(train[,10])
x4 <- as.numeric(train[,11])
x5 <- as.numeric(train[,12])
y <- as.numeric(train[,7])
fit <- lm(y ~ x1 + x2 + x3 + x4+x5)

```



```{r}
yhat <- predict(fit)
yhat <- round(yhat,0)
y <- round(y, 0)
cat("Linear regression prediction error in train:",1-mean(yhat==y),"\n")

```



```{r}
colshat <- yhat
colshat[yhat>=0.5] <- mycols[2]
colshat[yhat<0.5] <- mycols[1]
m1 <- -fit$coef[2]/fit$coef[6] #boundary slope
m2 <- -fit$coef[3]/fit$coef[6] #boundary slope

m3 <- -fit$coef[4]/fit$coef[6] #boundary slope

m4 <- -fit$coef[5]/fit$coef[6] #boundary slope


b <- (0.5 - fit$coef[1])/fit$coef[6] #boundary intercept

```


```{r}

##prediction on test
x11<- as.numeric(test[,8])
X22<-as.numeric(test[,9])
x33 <- as.numeric(test[,10])
x44 <- as.numeric(test[,11])
x55 <- as.numeric(test[,12])
yhat <- predict(fit,newdata=data.frame(x1=X11,x2=X22, x3=x33, x4=x44, x5=x55))
yhat <- as.numeric(yhat>0.5)
cat("Linear regression prediction error in test:",1-mean(yhat==ytest),"\n")

```


Recall when using random forest starting from numerical variables


```{r}
colgtotalup <- colgtotal[,-7]

```



```{r}
colg_imp <- filterVarImp(x = colgtotalup[,7:11], y = colgtotal$Project)

#sort the score in decreasing order
colg_imp <- data.frame(cbind(variable = rownames(colg_imp), score = colg_imp[,1]))
colg_imp$score <- as.double(colg_imp$score)
colg_imp[order(colg_imp$score,decreasing = TRUE),]

```

By the scores in amount, we use the randomForest method for feature selection instead


```{r}
library(dplyr)
colgadm2 <- colgtotal[,-7]

rf = randomForest(colgadm2[,3:11],as.numeric(colgtotal$Project))
colg_imp2 <- varImp(rf, scale = TRUE)

colg_imp_df <- data.frame(cbind(variable = rownames(colg_imp2), score = colg_imp2[,1]))
colg_imp_df$score <- as.double(colg_imp_df$score)
colg_imp_df[order(colg_imp_df$score,decreasing = TRUE),]

```


```{r}
ggplot(colg_imp_df, aes(x=reorder(variable, score), y=score)) + 
  geom_point() +
  geom_segment(aes(x=variable,xend=variable,y=0,yend=score)) +
  ylab("Impact Level") +
  xlab("Variable Name") +
  coord_flip()


```


Now, we use the selected features to predict by applying to knn


```{r}
set.seed(1)
sample <- sample(c(TRUE, FALSE), nrow(colgtotalup), replace=TRUE, prob=c(0.7,0.3))
trainup  <- colgtotalup[sample, ]

testup   <- colgtotalup[!sample, ]

```


```{r}
dat <-trainup
x<-data.frame(sapply(dat[,3:11], as.numeric))

y<-as.numeric(train$Project)
xtest <- data.frame(sapply(testup[,3:11],as.numeric))
ytest<-as.numeric(test$Project)
library(class)
mypar(2,2)
for(k in c(1,80)) {
  ##predict on train
  yhat <- knn(x,x,y,k=k)
  cat("KNN prediction error in train:",1-mean((as.numeric(yhat)-1)==y),"\n")
  ##make plot
  yhat <- knn(x,xtest,y,k=k)
  cat("KNN prediction error in test:",1-mean((as.numeric(yhat)-1)==ytest),"\n")
}

```
The following is a comparison of two types of errors. They are respectively from train error, test error error. Bayer's error will be discussed in section 1.7.



3.1 Knn Model Prediction 
So far, we have used knn model for evaluating model performance. We will further predict after inputting new samples (9.6) using this model

```{r}
pdct <- knn(train = x, test= x, cl = y, k = 5)
mean(y!=pdct)

```



```{r}
library(caret)
set.seed(1)
idx <- createFolds(y, k=7)
sapply(idx, length)
head( x[idx[[1]], 1:3] ) 
```




```{r}
sapply(idx, function(i) table(y[i]))

```



```{r}
library(rafalib)
mypar()
xsd <- cmdscale(dist(x))
plot(xsd,col=as.fumeric(as.character(y)))
legend("topleft",levels(factor(y)),fill=seq_along(levels(factor(y))))

```




```{r}
pdct1 <- knn(train=xsd[ -idx[[1]] , ], test=xsd[ idx[[1]], ], cl=y[ -idx[[1]] ], k=5)
table(true=y[ idx[[1]] ], pdct1)
mean(y[ idx[[1]] ] != pdct1)

```



```{r}
for (i in 1:7) {
  pdct1 <- knn(train=xsd[ idx[[i]] , ], test=xsd[ -idx[[i]], ], cl=y[ idx[[i]] ], k=5)
  print(paste0(i,") error rate: ", round(mean(y[ -idx[[i]] ] != pdct1),4)))
}

```

```{r}
set.seed(1)
ks <- 1:12
res <- sapply(ks, function(k) {
  res.k <- sapply(seq_along(idx), function(i) {
    pdct1 <- knn(train=xsd[ -idx[[i]], ],
                test=xsd[ idx[[i]], ],
                cl=y[ -idx[[i]] ], k = k)

    mean(y[ idx[[i]] ] != pdct1)
  })
 
  mean(res.k)
})

```



```{r}
plot(ks, res, type="o",ylab="misclassification error")
```



```{r}
xsd <- cmdscale(dist(x),k=5)
set.seed(1)
ks <- 1:11
res <- sapply(ks, function(k) {
  res.k <- sapply(seq_along(idx), function(i) {
    pdct1 <-  knn(train=xsd[ idx[[i]], ],
                test=xsd[ -idx[[i]], ],
                cl=y[ idx[[i]] ], k = k)
    mean(y[ -idx[[i]] ] != pdct1)
  })
  mean(res.k)
})
plot(ks, res, type="o",ylim=c(0,0.50),ylab="misclassification error")

```

From the plot above, the best k value is 5 in one fold to achieve the minimum in error. In other words, we expect to use 5 features for conducting the analysis.


