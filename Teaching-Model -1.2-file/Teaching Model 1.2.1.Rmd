---
title: "Teaching Model1.2"
author: "Module2"
date: '2023-02-15'
output:
  html_document: default
  pdf_document: default
  word_document: default
---


2.1 Description of the Updated Dataset

Now, we begin to construct a model, typically linear model. Before doing so, we first give an experiment design for an updated dataset by starting checking its variation 
```{r}
library(dplyr)


```



```{r}
colgtotal<- read.csv("C:/Users/Jing Xie/Documents/R/Teaching Project/Proj 1/Data/colgtotal.csv")
bs <- filter(colgtotal, Major =='1')
lw<- filter(colgtotal, Major =='2')
md <- filter(colgtotal, Major =='3')
cp <- filter(colgtotal, Major =='4')
cmb<-bind_rows(list( "1"=bs, "2"=cp, "3"=lw, '4'=md) , .id="Major")


```


```{r}
#remove.packages("rlang")
#remove.packages("dplyr")

#install.packages("rlang")
#install.packages("dplyr")

library(rlang)
library(dplyr)

```

```{r}
library(ggplot2)
ggplot(cmb, aes(as.numeric(Mid.Test), colour=Major))+
  geom_freqpoly()
ggplot(cmb, aes(as.numeric(Mid.Test), colour=Major, y=..density..))+
    geom_freqpoly()
ggplot(cmb, aes(as.numeric(Participation, Mid.Test), color=Major))+
    geom_density(kernel="gaussian")
ggplot(cmb, aes(as.numeric(Project, Mid.Test), color=Major))+
    geom_density(kernel="gaussian")
```
The above plot shows the density of individual midterm performance when controlling for student intended majors. Major 4, major 3 and major 2 display an increase tendency to complete the project while not the major 1



```{r}
ggplot(cmb, aes(as.numeric(Project, Final.Score), color=Major))+
    geom_density(kernel="gaussian")
ggsave('project_final.pdf')
```
There is no apparent change regarding the final.



```{r}
ggplot(cmb, aes(as.numeric(Participation, Final.Score), color=Major))+
    geom_density(kernel="gaussian")
ggsave('parti_final.pdf')
```
Taking a consideration of participation, however, we find major 1, 2, and 3 have a good performance related to their paticipation while major 4 isn't.
```{r}
cmb$index <- 1:nrow(cmb)
```



```{r}
library(reshape2)
cmb_mod <-  melt(cmb, id.vars='index', 
                  measure.vars=c('quiz1', 'Mid.Test', 'HW', 'Participation', 'Final.Score'))
p<- ggplot(cmb_mod)+
  geom_boxplot(
    mapping=aes( 
      x = index,
      y = value, color =variable
    )
  )+
  coord_flip()+
  xlab("")+
  ylab("Final Test Evaluation")+
  theme_minimal()

print(p)
```


```{r}
ggplot(data=cmb, mapping=aes(x=Major, y=Final.Score))+geom_boxplot()

```

2.2 Modeling Testing Method
After getting acknowledging about the new dataset, we start to build a model. The following script is to create a model that is used to find the predict of y.

2.2.1 Experiment Design
```{r}
gd <- colgtotal$Gender
rc <- colgtotal$Race
mj <- colgtotal$Major
gl <- colgtotal$Goal
pj <- colgtotal$Project
model.matrix(~gd+rc+mj+gl+pj, data=colgtotal)

```
The first model contain multiple features

Check the collinearity so that we are able to construct a model. Here, student goal might have effect to reach the collinearity. As a result of the variable goal, which causes collinarity, we prefer using PCA

```{r}
q<- colgtotal$quiz1
C <- model.matrix(~gd+rc+mj+gl+pj-1, data=colgtotal)
c <- model.matrix(~gd+rc+mj+pj-1, data=colgtotal)


cat("ncol=",ncol(C),"rank=", qr(C)$rank,"\n")
cat("ncol=",ncol(c),"rank=", qr(c)$rank,"\n")

```



```{r}
model1 <- lm(colgtotal$Final.Score~gd+rc+mj+gl+pj)
install.packages("olsrr")
library(olsrr)
```


```{r}
ols_coll_diag(model1)

```

```{r}
summary(model1)

```


```{r}
model2 <- lm(colgtotal$Final.Score~gd+rc+mj+gl+pj+colgtotal$quiz1+colgtotal$HW+colgtotal$Participation+ colgtotal$Mid.Test)
ols_coll_diag(model2)


```
```{r}
summary(model2)

```
The VIF values about the features have indicated to us the non collinearity, which we use to construct the linear model1 and model2. 
We found mid-test has high collinearity with other feature variables. 
In this dataset, to our surprise, gender and major as well as project factors both take significant place. Numerical variables such as quiz1, but not mid-test also play a significant role.
Now we begin to construct alternative models before we check models performance.  

```{r}
library(tidyverse)
is.na(colgtotal) <-sapply(colgtotal, is.infinite)
newcolgadm <- na.omit(colgtotal)
matcolgadm<-data.matrix(newcolgadm[, 3:12])

```



```{r}
set.seed(1)
a<- standardize(as.numeric(sample(colgtotal$Final.Score),15))
hist(a, breaks = 20,
main = "Final Score Distribution",
xlab = "Simulated Final Score",
col = "dodgerblue",
border = "darkorange")
```


Let's take a break at the process of constructing a model for fitting the data.

Before considering build up information to create a model. First, we need to verify the significance of column variables by considering t tests. Previously, we use VIF method to model1 and model2.  





```{r}
fg <- colgtotal%>%select('Gender', 'Final.Score')
fp <- colgtotal%>%select('Project', 'Final.Score')
mp <- colgtotal%>%select('Project', 'Mid.Test')

```




```{r}
fg <- data.matrix(fg)
set.seed(1)
N = 10
B = 100000
fgpvals <- replicate(B,{
  mal = sample(fg,N)
  fmal = sample(fg,N)
  t.test(mal,fmal)$p.val 
  })
hist(fgpvals, main = 'Student Gender and Final Performance')

```



```{r}
fp <- data.matrix(fp)
set.seed(1)
N = 10
B = 100000
fppvals <- replicate(B,{
  pj0 = sample(fp,N)
  pj1 = sample(fp,N)
  t.test(pj0,pj1)$p.val 
  })
hist(fppvals, main = 'Student Project and Final Performance')

```





```{r}
mp <- data.matrix(mp)
set.seed(1)
N = 10
B = 100000
mppvals <- replicate(B,{
  pj0 = sample(mp,N)
  pj1 = sample(mp,N)
  t.test(pj0,pj1)$p.val 
  })
hist(mppvals, main = 'Student Project and Mid Perforamnce')

```
The above plots uniformly indicate the variable such as gender and project provide the uniform-like sense about student academics in mid and in final. In this test, we use t test(as previously assumed normal distribution for samples we extracted). We have no concerns about the independence of each experiment we made, and the test follows normal distribution.



Then we start to test each feature and sample in the dataset below.
```{r}
cladm <- colgtotal[,8:12]
cladm <- apply(as.matrix(colgtotal[, 8:12]), 2, as.numeric)

```



```{r}
cladmttest <- function(x) t.test(x[gd==1],x[gd==0],var.equal=TRUE)$p.value
cladmpvals1 <- apply(cladm,1,cladmttest)
cladmpvals2 <- apply(cladm,2,cladmttest)

cladmpvals1
cladmpvals2
sum(cladmpvals1<0.05)
sum(cladmpvals2 < 0.05)     # By columns
```
from the above, where we only care about feature columns regarding p values, we conclude in term of the gender only, We see the roles of quiz1 and Final.score have significant impact.  

```{r}
cladmttestPJ <- function(x) t.test(x[pj==1],x[pj==0],var.equal=TRUE)$p.value
cladmpvals3 <- apply(cladm,1,cladmttestPJ)
cladmpvals4 <- apply(cladm,2,cladmttestPJ)    # By columns

cladmpvals3
cladmpvals4
sum(cladmpvals3<0.05)
sum(cladmpvals4<0.05)

```
In term of project, more column variables show their significance level than in term of the gender (Multiple Test). They are quiz1, Mid.Test, HW, Final.Score respectively.


```{r}
#nullpvals <- colttests(randomData,h)$p.value
library(rafalib)
mypar(1,2)
plot(cladmpvals1,-log10(cladmpvals1),
     xlab="Effect size",ylab="- log (cladmpvals1) p-values")

plot(cladmpvals3,-log10(cladmpvals3),
     xlab="Effect size",ylab="- log (cladmpvals3) p-values")


``` 
The two plots above are effect size for row samples, which is off our current topic. The following two plots below, however, is within our consideration.
```{r}
library(rafalib)
mypar(1,2)
#nullpvals <- colttests(randomData,h)$p.value
plot(cladmpvals2,-log10(cladmpvals2),
     xlab="Effect size",ylab="- log (cladmpvals2) p-values")

#nullpvals <- colttests(randomData,h)$p.value
plot(cladmpvals4,-log10(cladmpvals4), xlim = c(0, 1),          # Consider column features
     xlab="Effect size",ylab="- log (cladmpvals4) p-values")

```  
The two plots above indicate the effect size of column variables. From the plot on the left side, we see there are at least 3 variables in columns have bigger effect size. From gender perspective, mid test and final test are found to be impacted. (multiple test). Regarding the plot in the right side, it is about the effect size in term of project. If we random take samples, as shown below, We reject the null hypothesis, confirming the impact of gender and project at a significant level.


```{r}
set.seed(1)
library(genefilter)
u <- nrow(colgtotal)
v <- ncol(colgtotal[,8:12])
randomcladm <- matrix(rnorm(u*v),u,v)
cladmttest <- function(x) t.test(x[gd==1],x[gd==0],var.equal=TRUE)$p.value
cladmnulpval2 <- apply(randomcladm,2,cladmttest)
cladmnulpval1 <- apply(randomcladm,1,cladmttest)
cladmnulpval2
cladmnulpval1
which(cladmnulpval1 < 0.05)   
which(cladmnulpval2 < 0.05)

```


```{r}
cladmttestPJ <- function(x) t.test(x[pj==1],x[pj==0],var.equal=TRUE)$p.value
cladmnulpval5 <- apply(randomcladm,1,cladmttestPJ)
cladmnulpval6 <- apply(randomcladm,2,cladmttestPJ)

cladmnulpval5
cladmnulpval6
which(cladmnulpval5 < 0.05)   
which(cladmnulpval6 < 0.05)

```

```{r}
library(rafalib)
mypar(1,2)

plot(cladmnulpval2,-log10(cladmnulpval2),
     xlab="Effect size",ylab="- log (cladmnulpval2) p-values")  # for randomness
plot(cladmpvals2,-log10(cladmpvals2),               # for particular sample
     xlab="Effect size",ylab="- log (cladmpval2) p-values")

```


```{r}
library(rafalib)
mypar(1,2)

plot(cladmnulpval6,-log10(cladmnulpval6),
     xlab="Effect size",ylab="- log (cladmnulpval6) p-values")  # for randomness
plot(cladmpvals4,-log10(cladmpvals4),               # for particular sample
     xlab="Effect size",ylab="- log (cladmpval4) p-values")

```


The above tests are model analysis in term of gender and project respectively, where we have 90 percent of confidence to reveal more than 4 column variables for both models are significant, in which randomness cases (nulpval2 or nulpval4) as good as the specified case(pval4 or pval6); however, we expect the more outcomes with the confidence level from the observs in addition to its its effect size against p values. Now we will further consider other methods than the t test (multiple test)


The following aims at finding group and individual activity results 

```{r}
library(genefilter)
```




```{r}
library(rafalib)
mypar(1,2)
gd <- factor(gd)
pj <- factor(pj)
colgtotal <- apply(as.matrix(colgtotal), 2, as.numeric)
coladmresults1<- rowttests(t(colgtotal), gd)
coladmresults2 <- rowttests(t(colgtotal), pj)
plot(coladmresults1$dm,-log10(coladmresults1$p.value),
     xlab="Effect size",ylab="- log (coladmresults1$p.value) p-values")
plot(coladmresults2$dm,-log10(coladmresults2$p.value),
     xlab="Effect size",ylab="- log (coladmresults2$p.value) p-values")

```
When using fast method to find effect size besides p value, the highly significance is located on the top, which approximately are about 4 of column variables.  We also have an interest in plotting both histogram under the condition to check if its uniform

```{r}
h <- nrow(colgtotal)
k <- ncol(colgtotal)
randomcladm <- matrix(rnorm(h*k),h,k)
coladmresultsnullpvalsgd <- rowttests(t(randomcladm),gd)$p.value

coladmresultsnullpvalspj <- rowttests(t(randomcladm),pj)$p.value
```

In the following two plots, we see the significant small p values, which we use to reject the null hypothesis. That is, with respect to gender factor, we do find the impact from the current setting.
```{r}
library(rafalib)
mypar(1,2)
hist(coladmresultsnullpvalsgd,ylim=c(0,15), main = 'Null of p values')
hist(coladmresults1$p.value,ylim=c(0,15), main = 'p values')

```
```{r}
library(rafalib)
mypar(1,2)
hist(coladmresultsnullpvalspj,ylim=c(0,15), main = 'Null of p values')
hist(coladmresults2$p.value,ylim=c(0,15), main = 'p values')

```
The project model also reveals the similar impact from student project work.

Moreover, the null matrix is uniform, but the pvalues are not. We need to find correlated variables to generalize a better model. The above plots show project factor is found significant to impact student performance (nullpvale is nearly uniform, but its alternative isn't, which indicates there are some correlations within the coladmresults dataset as we found the high error rate, more than 50% are false positive )


